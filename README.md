**ğŸ™ï¸ Real-Time Speech Emotion & Sentiment Detection**

This project is a real-time English speech transcription system with integrated sentiment and emotion detection, powered by NLP transformer models, Google Speech Recognition, and a Streamlit interface.

**ğŸ“– Project Description**

The application allows users to:

ğŸ¤ Transcribe live audio from the microphone or upload .wav audio files

âœï¸ Restore proper punctuation using a multilingual punctuation model

ğŸ˜Š Analyze emotions (like Joy, Sadness, Anger) based on context

ğŸ‘ Perform sentiment classification (Positive, Negative)

ğŸ“Š Ensure consistent interpretation by aligning sentiment with emotion

All results are displayed live in an interactive Streamlit UI, providing a real-time emotional overview of spoken content.


**ğŸ” Key Features**
âœ… Live microphone input and audio file upload support

âœ… Real-time speech-to-text transcription (via Google Speech API)

âœ… Automatic punctuation restoration with multilingual model

âœ… Accurate sentiment analysis using Hugging Face pipelines

âœ… Deep emotion detection using DistilRoBERTa emotion classifier

âœ… Streamlit interface with live updates and visual display

**ğŸ§  Models and Tools Used**

Component	Library/Model
Speech Recognition	speech_recognition (Google Web Speech API)
Sentiment Analysis	transformers - pipeline("sentiment-analysis")
Emotion Detection	j-hartmann/emotion-english-distilroberta-base (via Hugging Face)
Punctuation Restore	deepmultilingualpunctuation - oliverguhr/fullstop-punctuation-multilang
UI Framework	streamlit

**â–¶ï¸ How to Run**

1. ğŸš€ Start the Application

streamlit run speech_module.py


**âœ… Advantages**

ğŸ”„ Real-time audio-to-text processing

ğŸ§  Deeper emotional context than basic transcription

ğŸ” Consistent emotion-sentiment alignment logic

ğŸ–±ï¸ No code knowledge required â€“ fully GUI-based

ğŸŒ Can be adapted to other languages or domains

